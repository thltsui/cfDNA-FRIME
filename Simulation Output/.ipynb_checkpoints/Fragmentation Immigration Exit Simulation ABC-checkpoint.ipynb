{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b8482a",
   "metadata": {},
   "source": [
    "# Fragmentation with Immigration and Exit Simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd186f42",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We now introduce a fragmentation with immigration and exit process that will serve as a toy model to understand mitochondrial cell-free DNA fragmentomics.\n",
    "\n",
    "### Biological Background and Motivation\n",
    "Cell-free DNAs (cfDNAs) are DNA strands that are continuously released by blood cells, cancer cells or bone marrow cells into the blood stream (Immigration). In the blood stream, these cfDNAs will come into contact with DNA-se (DNA breaking proteins) that will break them into smaller pieces (Fragmentation). Finally, cfDNAs that are small enough will exit the blood stream through our urinary system or liver absorption (Exit Mechanism).\n",
    "\n",
    "As cfDNA sampling technology matures, one can now easily draw blood samples and analyse a patient's cfDNA fragments data. Nowadays, cfDNA data can even be used to diagnosis presence of tumours. Understanding the mechanism where fragment patterns arise may serve as a potential diagnostic tool. To do so, one may consider a patient's cfDNA fragmentation pattern as a equilibrium state that arises from the rapid reactions from the 3 mechanisms described above. \n",
    "\n",
    "As a result, in this notebook, we want to check under what simple model assumptions there exists a stationary distribution for a fragmentation with immigration and exit process.\n",
    "\n",
    "\n",
    "### Mathematical Model\n",
    "\n",
    "For simplicity, we assume that the longest possible cfDNA strand is of length 1 (after renormalisation).\n",
    "\n",
    "We will also assume that the fragmentation process is uniform, i.e. the protein breaks the cfDNA into two parts at a randomly chosen location on the cfDNA strand. Note that this assumption does not hold true for genomic cfDNA.\n",
    "\n",
    "We will also assume that the cfDNA strand has large number of base pairs, such that under renormalisation, we may treat cfDNA strands as continuous threads. In other words, we assume that there are infinitely many potential sites of fragmentation.\n",
    "\n",
    "We will measure time at the scale of fragmentation, and we will assume that the fragmentation is homogeneous, i.e. a cfDNA strand of length $\\ell$ will on average take $\\ell$ unit of time to be broken into smaller pieces. Explicitly, we assume that strands independently splits into smaller pieces with exponential rate proportional to their lengths.\n",
    "\n",
    "We will also assume that immigration of new cfDNA strands follow a Poisson point process. At some rate $immrate$, a random number $Nimm$ many fragments are immigrated into the system.\n",
    "\n",
    "Finally, to model exit mechanism, we will assume that smaller fragments are more likely to exit the system than longer fragments. To do so, we assume a simple linear model between rates of exit and lengths of the fragment. Specifically, \n",
    "we assume that a fragment of length $\\ell$ will leave the system at rate $ex_{max} - ex_{slope} \\ell$ if such rate is positive. Otherwise, if $ex_{max} - ex_{slope} \\ell < 0$, a fragment of length $\\ell$ will not exit the system.\n",
    "\n",
    "\n",
    "Under these assumptions, one can model the whole system of fragments as an element of $[0,1]^{\\mathbb{N}}$, which corresponds to a list of fragment lengths between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d24be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib\n",
    "import math\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57881a",
   "metadata": {},
   "source": [
    "## Defining the Fragmentation Mechanism\n",
    "\n",
    "Each fragment is described by two numbers, its length that is between 0 and 1, and a neutral marker uniformly sampled between 0 and 1. \n",
    "\n",
    "Whenever a fragment splits into smaller pieces, the smaller fragments inherit the same neutral marker as the original fragment. \n",
    "\n",
    "Therefore, the whole Fragment List (Frag_List) will have two attributes, Frag_lens and Frag_labs for lengths and labels\n",
    "\n",
    "Here, we define multiple functions that are essential to calculating the rates at which immigration, fragmentation and exit events occur.\n",
    "\n",
    "These functions are then used to define frag_mechan which determines whether fragmentation, immigration or exit occurs for a list of fragments, and what happens to the list of fragments subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd3beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frag_List:\n",
    "    \n",
    "    def __init__(self, Frag_lens, Frag_labs):\n",
    "        self.Frag_lens=Frag_lens\n",
    "        self.Frag_labs=Frag_labs\n",
    "        \n",
    "    def __str__(self):\n",
    "        information = f\"Fragmentation lengths = {self.Frag_lens}, Fragmentation Labels = {self.Frag_labs}\"\n",
    "        return information    \n",
    "   \n",
    "      \n",
    "    def exit_params(self, ex_max, ex_slope):\n",
    "        \"ex_params gives the time for first exit of a fragment from a Frag_list, the exit rate of each fragment according to its length for a list of fragments, and the renormalised exit probability Here we assume the exit rate linearly decreases with fragment lengths. ex_max: maximum rate, ex_slope: slope of decay\"\n",
    "        exit_rates=ex_max*np.ones(len(self.Frag_lens))-ex_slope*self.Frag_lens\n",
    "        exit_rates[exit_rates<=0]=0.001 #Prohibit negative exit rates\n",
    "        exit_time = np.random.exponential(1/np.sum(exit_rates))\n",
    "        exit_prob = exit_rates/np.linalg.norm(exit_rates,1)\n",
    "        return exit_time, exit_rates, exit_prob\n",
    "    \n",
    "    def frag_time(self,frag_speed):\n",
    "        \"frag_time gives the next fragmentation time given list of fragments. fragments: np-array of all fragments lengths, speed: rate at which fragments split\"\n",
    "        return np.random.exponential(1/(frag_speed*np.sum(self.Frag_lens)))\n",
    "    \n",
    "    def imm_time(self, imm_rate):\n",
    "        \"imm_time gives next immigration time, which is exponential with imm_rate\"\n",
    "        return np.random.exponential(1/imm_rate)\n",
    "    \n",
    "    def imm(self, new_Frags):\n",
    "        \"Add new_Frags into existing fragment lists\"\n",
    "        self.Frag_lens= np.append(self.Frag_lens,new_Frags.Frag_lens)\n",
    "        self.Frag_labs= np.append(self.Frag_labs,new_Frags.Frag_labs)    \n",
    "    \n",
    "    def exit(self, ex_max, ex_slope):\n",
    "        \"This function deletes a fragment from the list with probability proportional to its exit rates\"\n",
    "        exit_prob=self.exit_params(ex_max, ex_slope)[2]\n",
    "        frag_gone=np.random.choice(self.Frag_lens.size,1, p=exit_prob)[0] #the gone fragment is chosen with probability proportional to exit_prob\n",
    "        #print(frag_gone)\n",
    "        self.Frag_lens=np.delete(self.Frag_lens,frag_gone) #gone fragment deleted from existing system\n",
    "        self.Frag_labs=np.delete(self.Frag_labs,frag_gone) #gone fragment deleted from existing system\n",
    "    \n",
    "    def split(self, N_split):\n",
    "        frag_prob=self.Frag_lens/np.linalg.norm(self.Frag_lens,1)\n",
    "        i = np.random.choice(self.Frag_lens.size, 1, p=frag_prob)[0] #i-th fragment fragments\n",
    "        #print(i)\n",
    "        gone_frag_lens=self.Frag_lens[i]\n",
    "        inherited_lab = self.Frag_labs[i]\n",
    "        frag_interval=np.array([0,self.Frag_lens[i]]) \n",
    "        frag_site=np.sort(np.append(np.random.uniform(0,self.Frag_lens[i],N_split-1),frag_interval)) #splitting positions are uniformly distributed \n",
    "        new_frag_lens=np.diff(frag_site)\n",
    "        new_frag_labs=self.Frag_labs[i]*np.ones(len(new_frag_lens))\n",
    "        self.Frag_lens = np.append(np.delete(self.Frag_lens,i),new_frag_lens)\n",
    "        self.Frag_labs = np.append(np.delete(self.Frag_labs,i),new_frag_labs)\n",
    "    \n",
    "    def FragExIm(self, ex_max, ex_slope, frag_speed, N_split, Nimm, imm_rate):\n",
    "        event_times = np.asarray([self.frag_time(frag_speed), self.imm_time(imm_rate), self. exit_params(ex_max,ex_slope)[0]])\n",
    "        next_event=np.where(event_times == np.amin(event_times))[0]\n",
    "        if next_event[0]==0:\n",
    "            Event= \"fragmentation\"\n",
    "            self.split(N_split)\n",
    "        elif next_event[0]==1:\n",
    "            Event= \"exit\"\n",
    "            self.exit(ex_max, ex_slope)\n",
    "        else:\n",
    "            Event= \"Immigration\"\n",
    "            new_Frags = Frag_List(np.random.uniform(0,1,Nimm),np.ones(Nimm)*np.amin(event_times))\n",
    "            self.imm(new_Frags)\n",
    "        #print(f\"Event = {Event}, Event Time = {np.amin(event_times): .3f}\")    \n",
    "        return Event, np.amin(event_times)\n",
    "    \n",
    "    \n",
    "############################################################################################################################################\n",
    "################Fragmentation Statistics###########\n",
    "#Here we define functions that give important statistics on a list of fragmentation lengths.\n",
    "#They include a function that gives the cumulative distribution (or count) of fragment lengths of the list, a function that produces the empirical density / empirical mass of the fragment distribution, and a function that produces the Kolomogorov-Smirnov Distance between two empirical distributions / empirical mass.\n",
    "\n",
    "    def mean(self):\n",
    "        return np.mean(self.Frag_lens)\n",
    "    \n",
    "    def cum_dist(self, N_Group, count=False): \n",
    "        \"cum_dist gives the empirical cumulative distribution function of fragment lengths given a list of fragments with N_Group data points, if count=True, cumulative count is given instead\"\n",
    "        N_tiles=np.linspace(0,1,N_Group+1)\n",
    "        #print(N_tiles)\n",
    "        cum_count=np.asarray([np.count_nonzero(self.Frag_lens<=i) for i in N_tiles])\n",
    "        cum_dist=cum_count/cum_count[-1]\n",
    "        if count:\n",
    "            output = cum_count\n",
    "        else:\n",
    "            output = cum_dist\n",
    "        return  output\n",
    "    \n",
    "    def density(self, N_Group, count=False):\n",
    "        \"density gives the empirical density of a sample, if count=True, empirical mass function is given instead\"\n",
    "        return np.diff(self.cum_dist(N_Group,count))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6604d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragmentation lengths = [0.52034989 0.35298162 0.53814495 0.30610653 0.40966569 0.2865473\n",
      " 0.04169176 0.36922484 0.36993947 0.12445502 0.64019533 0.30065209\n",
      " 0.72945415 0.62409489 0.37009677 0.55381149 0.78146335 0.72695862\n",
      " 0.98637207 0.59005448 0.16243754 0.58806966 0.87487426 0.45248323\n",
      " 0.5358213  0.69488726 0.41736888 0.15115307 0.46737416 0.36581186\n",
      " 0.23244762 0.91131786 0.91343598 0.25988497 0.76133469 0.66080938\n",
      " 0.33491966 0.74125356 0.02505232 0.6868749  0.51738747 0.91097759\n",
      " 0.3732439  0.13670625 0.13966281 0.7210096  0.2809956  0.78706779\n",
      " 0.87434918 0.18059989 0.58777484 0.69465444 0.1481152  0.55534788\n",
      " 0.89146573 0.55244621 0.51628054 0.17772891 0.74541331 0.91953247\n",
      " 0.72270945 0.78309008 0.98673416 0.41849314 0.20793585 0.37304987\n",
      " 0.16127619 0.75787188 0.07220013 0.5167413  0.55074629 0.36312445\n",
      " 0.55576573 0.30821756 0.16984657 0.29530351 0.45079664 0.84139585\n",
      " 0.02298164 0.69651126 0.16874907 0.55645509 0.27773165 0.39137624\n",
      " 0.5468212  0.04243115 0.12482438 0.85661978 0.13316805 0.87736516\n",
      " 0.764536   0.1600593  0.72922296 0.26898847 0.32320377 0.1574043\n",
      " 0.03271011 0.80549856 0.91609949 0.71928862 0.45268028], Fragmentation Labels = [0.40331304 0.59109735 0.34764856 0.15580117 0.43351377 0.28191357\n",
      " 0.64155115 0.22133253 0.1086259  0.04565445 0.98913411 0.25451314\n",
      " 0.72426795 0.41991688 0.25728648 0.0056695  0.10089802 0.70065315\n",
      " 0.40603554 0.23221851 0.30287356 0.44111302 0.76436351 0.96137937\n",
      " 0.57817295 0.7089214  0.33098708 0.39676901 0.89871088 0.43676794\n",
      " 0.59377273 0.50597542 0.21556908 0.79064743 0.27482282 0.94403834\n",
      " 0.71648751 0.79433279 0.77900328 0.8077399  0.89076814 0.96990327\n",
      " 0.94700224 0.19265761 0.19675629 0.41268405 0.90460422 0.75189402\n",
      " 0.58647406 0.84374471 0.78492796 0.76800348 0.80974178 0.21232298\n",
      " 0.67632461 0.6967565  0.0341195  0.96930032 0.52348448 0.30045433\n",
      " 0.57137023 0.76016065 0.40208492 0.8175044  0.69082673 0.3643148\n",
      " 0.04814526 0.24710223 0.28212658 0.31298508 0.70087498 0.16010478\n",
      " 0.75138541 0.216374   0.31531705 0.85249444 0.24176682 0.84884513\n",
      " 0.28890805 0.36122894 0.7805454  0.53805033 0.11260486 0.86039705\n",
      " 0.10736335 0.00249544 0.24729097 0.78931074 0.51529795 0.51592652\n",
      " 0.97402525 0.6480019  0.83894649 0.70072355 0.49632661 0.68185348\n",
      " 0.88882781 0.48496439 0.34068829 0.55748603 0.00110853] Immigration 0.0011085349982273966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4864421511936966"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Frag_List(np.random.uniform(0,1,100),np.random.uniform(0,1,100))\n",
    "#print(x)\n",
    "#print(x)\n",
    "Event, Event_time = x.FragExIm(4,2,1,2,1,5)\n",
    "print(x, Event, Event_time)\n",
    "x.mean()\n",
    "#print(x.cum_dist(5))\n",
    "#print(x.cum_dist(5, count=True))\n",
    "#print(x.density(5), x.density(5,count=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a2099",
   "metadata": {},
   "source": [
    "## Fragmentation Statistics\n",
    "\n",
    "Here we define functions that give important statistics on a list of fragmentation lengths. They include a function that gives the cumulative distribution (or count) of fragment lengths of the list, a function that produces the empirical density / empirical mass of the fragment distribution, and a function that produces the Kolomogorov-Smirnov Distance between two empirical distributions / empirical mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad61560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KS_Dist(cum_dist1,cum_dist2):\n",
    "    \"Kolmogorov-Smirnov Distance of two empirical distributions\"\n",
    "    return np.max(np.abs(cum_dist1-cum_dist2))\n",
    "\n",
    "def total_len_growth(frag_1,frag_2):\n",
    "    \"Returns the growth rate from frag_1 to frag_2\"\n",
    "    return np.sum(frag_2)/np.sum(frag_1)-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b108b4",
   "metadata": {},
   "source": [
    "## Running One Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59f45b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time= 1.00, #Events=3204\n",
      "distance is 0.024\n",
      "59406\n",
      "Time= 2.00, #Events=117718\n",
      "distance is 0.001\n",
      "55092\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24048/1847998714.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mEvent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFragExIm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mTime_db\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvent_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24048/127711941.py\u001b[0m in \u001b[0;36mFragExIm\u001b[1;34m(self, ex_max, ex_slope, frag_speed, N_split, Nimm, imm_rate)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mFragExIm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrag_speed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNimm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimm_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mevent_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrag_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrag_speed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimm_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimm_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mexit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mex_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mnext_event\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_times\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnext_event\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24048/127711941.py\u001b[0m in \u001b[0;36mexit_params\u001b[1;34m(self, ex_max, ex_slope)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;34m\"ex_params gives the time for first exit of a fragment from a Frag_list, the exit rate of each fragment according to its length for a list of fragments, and the renormalised exit probability Here we assume the exit rate linearly decreases with fragment lengths. ex_max: maximum rate, ex_slope: slope of decay\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mexit_rates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mex_max\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFrag_lens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mex_slope\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFrag_lens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mexit_rates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexit_rates\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m \u001b[1;31m#Prohibit negative exit rates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mexit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexit_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=Frag_List(np.random.uniform(0,1,100),np.zeros(100))\n",
    "d = 1\n",
    "T=0\n",
    "iteration=0\n",
    "N_Group = 10\n",
    "Frag_db=[[x.Frag_lens,x.Frag_labs]]\n",
    "Time_db=[]\n",
    "while KS_dist > 1000:\n",
    "    old_mean = x.mean()\n",
    "    old_cum_dist = x.cum_dist(N_Group,count=True)\n",
    "    k=0\n",
    "    while k < 1:\n",
    "        Event, Event_time = x.FragExIm(4,2,1,2,1,5)\n",
    "        Time_db.append(Event_time)\n",
    "        iteration +=1\n",
    "        k += Event_time\n",
    "        T += Event_time        \n",
    "    KS_dist = KS_Dist(old_Frag.cum_dist(N_Group, count=True),x.cum_dist(N_Group,count=True))\n",
    "    Frag_db.append([x.Frag_lens,x.Frag_labs])\n",
    "    print(f\"Time= {T:.2f}, #Events={iteration}\")\n",
    "    d = abs(old_mean-x.mean())\n",
    "    print(f\"distance is {d:.3f}\")\n",
    "    print(KS_dist)\n",
    "\n",
    "    \n",
    "#Frag_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a7dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x193a54b9a90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y=Frag_List(Frag_db[2][0],Frag_db[2][1])\n",
    "plt.plot(np.linspace(0,1,101),y.cum_dist(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaab7686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0  16505  31859  45751  58592  70817  81840  92213 101885 110931\n",
      " 119439] [     0  16505  31859  45751  58592  70817  81840  92213 101885 110931\n",
      " 119439]\n"
     ]
    }
   ],
   "source": [
    "print(old_Frag.cum_dist(N_Group, count=True),\n",
    "x.cum_dist(N_Group, count=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf112324",
   "metadata": {},
   "source": [
    "## Sampling 200 Simulations\n",
    "In this part of the jupyter notebook, we run 200 simulations of our fragmentation, immigration and exit process.\n",
    "\n",
    "We run each of the 200 processes up to time 15, and store the list of fragments at 5 time points. We also store the Kolmogorov-Smirnov distance of the cumulative fragmentation distributions between two time steps. They will be useful in understanding how well-mixed the Markov chain is.\n",
    "\n",
    "We start our simulation at random initial data with 50-200 initial fragments, each distributed between 0 and 1 uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b121ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 50\n",
    "frag_speed = 10\n",
    "Nsplit = 2\n",
    "ex_max=2\n",
    "ex_slope=100\n",
    "Nimm = 1\n",
    "imm_rate = 1\n",
    "Max_time=15\n",
    "Big_time=0\n",
    "N_Group = 50\n",
    "time_series_points = 5\n",
    "Big_time_scale = Max_time/time_series_points\n",
    "sample_num = 0\n",
    "Frag_time_series=[ [0]*(time_series_points+1) for i in range(N_sample)]\n",
    "#print(Frag_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = np.ones(100)\n",
    "\n",
    "new_frags_1=frag_mechan(fragments, 2,4, 0.5, 4, 5, 20)\n",
    "\n",
    "print(new_frags_1)\n",
    "new_frags_2=frag_mechan(fragments, 2,4, 0.5, 4, 5, 20)\n",
    "\n",
    "cum2dens(cum_dist(new_frags_1[2], 20)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a99179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################\n",
    "#fig, axs = plt.subplots(N_sample)\n",
    "\n",
    "KS_dataset=[]\n",
    "l2_dataset=[]\n",
    "iter_dataset=[]\n",
    "while sample_num < N_sample:\n",
    "    N_frag=np.random.randint(50,200) # Total number of Fragments initially\n",
    "    fragments = np.random.uniform(0,1,N_frag)\n",
    "    time=0\n",
    "    KS_data=[]\n",
    "    length_data = []\n",
    "    l2_data=[]\n",
    "    #print(Frag_time_series)\n",
    "    series_point=0\n",
    "    #fig, ax = plt.subplots(2)\n",
    "    iteration = 0 \n",
    "    while Big_time <= Max_time:\n",
    "        old_fragments=fragments\n",
    "        old_cum_count=cum_dist(old_fragments, N_Group)[1]\n",
    "        old_emp_mass=cum2dens(old_cum_count)[1]\n",
    "        while time < Big_time:\n",
    "            [Event, Event_time, fragments]= frag_mechan(fragments, ex_max, ex_slope, frag_speed, Nsplit, Nimm, imm_rate)\n",
    "            #print(Event)\n",
    "            iteration += 1\n",
    "            time = time + Event_time\n",
    "        Frag_time_series[sample_num][series_point]=fragments\n",
    "        new_cum_count=cum_dist(fragments, N_Group)[1]\n",
    "        new_emp_mass=cum2dens(new_cum_count)[1]\n",
    "        #len_growth = round(total_len_growth(old_fragments,fragments),2)\n",
    "        length=np.sum(fragments)\n",
    "        #growth_data = growth_data + [len_growth]\n",
    "        KS_dist = round(KS_Dist(old_cum_count,new_cum_count),2)\n",
    "        KS_data = KS_data + [KS_dist]\n",
    "        l2_dist = round(np.linalg.norm(old_emp_mass-new_emp_mass),2)\n",
    "        l2_data = l2_data + [l2_dist]     \n",
    "        x_axis_emp=np.linspace(0,1,num=N_Group)\n",
    "        x_axis_cum=np.linspace(0,1,num=N_Group+1)\n",
    "        #axs[sample_num].set_xlim(0, 1)\n",
    "        #axs[sample_num].set_ylim(0,50)\n",
    "        #axs[sample_num].plot(x_axis,emp_mass, label=\"T = \"+ str(Big_time) + \" l = \" + str(length) + \" l2 = \" + str(l2_dist))\n",
    "        #axs[sample_num].legend()\n",
    "        #ax[0].plot(x_axis_emp,new_emp_mass, label=\"T = \"+ str(Big_time) + \"it = \"+ str(iteration) + \" l = \" + str(round(length,1)) + \" l2 = \" + str(l2_dist))\n",
    "        #ax[0].set_xlim(0,1)\n",
    "        #ax[0].set_ylim(0,40)\n",
    "        #ax[0].legend(loc=1, prop={'size': 6})\n",
    "        #ax[0].set_title(\"Sample:\" + str(sample_num))\n",
    "        #ax[1].plot(x_axis_cum,new_cum_count, label=\"T = \"+ str(Big_time) + \"it = \"+ str(iteration) +  \" l = \" + str(round(length,1)) + \" KS = \" + str(KS_dist))\n",
    "        #ax[1].set_xlim(0,1)\n",
    "        #ax[1].set_ylim(0,300)\n",
    "        #ax[1].legend(loc=2, prop={'size': 6})\n",
    "        #ax[1].set_title(\"Sample:\" + str(sample_num))\n",
    "        #fig.tight_layout()\n",
    "        #display(fig)    \n",
    "        #clear_output(wait = True)\n",
    "        #plt.pause(0.1)\n",
    "        series_point = series_point + 1\n",
    "        Big_time=Big_time+Big_time_scale\n",
    "    #plt.show()\n",
    "    KS_dataset.append(KS_data)\n",
    "    l2_dataset.append(l2_data)\n",
    "    sample_num = sample_num+1\n",
    "    iter_dataset.append(iteration)\n",
    "    print(iteration)\n",
    "\n",
    "    \n",
    "%store Frag_time_series\n",
    "%store KS_dataset\n",
    "%store l2_dataset\n",
    "%store iter_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99200613",
   "metadata": {},
   "source": [
    "## Analysing the Sample Mean Fragmentation Distribution\n",
    "\n",
    "We aggregate all the fragmentation distributions across all 200 samples at each time point to visualise the Sample Mean Fragmentation Distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5602f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r\n",
    "N_Group = 20\n",
    "Frag_time_series, KS_data, l2_data\n",
    "x_axis_emp=np.linspace(0,1,num=N_Group)\n",
    "x_axis_cum=np.linspace(0,1,num=N_Group+1)\n",
    "total_cum_count=[]\n",
    "total_emp_mass = []\n",
    "mean_KS_dist =[]\n",
    "mean_l2_dist =[]\n",
    "\n",
    "Total_Frag = [Frag_time_series[0][i] for i in np.arange(time_series_points+1)]\n",
    "\n",
    "for j in np.arange(1,N_sample):\n",
    "    for k in np.arange(time_series_points+1):\n",
    "        Total_Frag[k]=np.concatenate((Total_Frag[k],Frag_time_series[j][k]))\n",
    "\n",
    "\n",
    "fig1, axs1 = plt.subplots()\n",
    "fig2, axs2 = plt.subplots()\n",
    "fig3, axs3 = plt.subplots()\n",
    "for t in np.arange(time_series_points+1):\n",
    "    total_cum_count.append(cum_dist(Total_Frag[t],N_Group)[1])\n",
    "    total_emp_mass.append(cum2dens(total_cum_count[t])[1])\n",
    "    mean_t_KS_dist = round(np.linalg.norm(total_cum_count[t]-total_cum_count[t-1],np.inf)/N_sample,1)\n",
    "    mean_t_l2_dist = round(np.linalg.norm(total_emp_mass[t]-total_emp_mass[t-1])/N_sample,1)\n",
    "    mean_KS_dist.append(mean_t_KS_dist)\n",
    "    mean_l2_dist.append(mean_t_l2_dist)\n",
    "    #plt.hist(Total_Frag[t],N_Group,label=\"T=\"+str(t*Big_time_scale))\n",
    "    axs1.plot(x_axis_emp, total_emp_mass[t]/N_sample,label=\"T=\"+str(t*Big_time_scale)+\", l2 =\"+ str(mean_t_l2_dist))\n",
    "    axs1.set_title(\"Mean Fragment Count\")\n",
    "    axs1.legend(loc=1, prop={'size': 8})\n",
    "    axs2.plot(x_axis_cum, total_cum_count[t]/N_sample,label=\"T=\"+str(t*Big_time_scale)+\", KS =\"+ str(mean_t_KS_dist))\n",
    "    axs2.set_title(\"Mean Fragment Cumulative Count\")\n",
    "    axs2.legend(loc=2, prop={'size': 8})\n",
    "    axs3.loglog(x_axis_emp, total_emp_mass[t]/N_sample,label=\"T=\"+str(t*Big_time_scale)+\", l2 =\"+ str(mean_t_l2_dist))\n",
    "    axs3.set_title(\"log-log Mean Fragment Count\")\n",
    "\n",
    "#time_axis=np.arange(time_series_points+1)*Big_time_scale   \n",
    "#axs2[0].plot(time_axis,mean_l2_dist, color = 'k')\n",
    "#axs2[0].set_title(\"Fragment Count l2 distance\")\n",
    "#axs2[0].set_ylim(0,20)\n",
    "#axs2[1].plot(time_axis,mean_KS_dist,  color = 'k')\n",
    "#axs2[1].set_title(\"Fragment Cumulative Count Sup Distance\")\n",
    "#axs2[1].set_ylim(0,100)\n",
    "#fig2.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede3f82",
   "metadata": {},
   "source": [
    "### Existence of Equilibrium Distribution\n",
    "Here we can clearly see that the mean fragment distribution looks almost the same when $T$ gets larger than 8. This is strong evidence to suggest convergence to a equilibrium distribution irregardless of initial condition. \n",
    "\n",
    "Note also that the l2-distance and KS-distance drops drastically to very small number too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f49c9a",
   "metadata": {},
   "source": [
    "## Fluctuation Around the Equilibrium Distribution\n",
    "\n",
    "We now quantify the fluctuation around the equilibrium distribution for a typical realisation. We calculate the l2 distance between a particular sample and the sample mean empirical distribution, as well as the KS distance of the cumulative distribution function. We then plot these statistics on a graph.\n",
    "\n",
    "NOTE: The code below gives nice visualisation of the process but will take time. Hide all the plotting if you do not want to waste computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_emp_mass = [i / N_sample for i in total_emp_mass]\n",
    "average_emp_mass[1]\n",
    "average_cum_count = [i / N_sample for i in total_cum_count]\n",
    "sample_l2 =[]\n",
    "sample_ks =[]\n",
    "x_axis_emp=np.linspace(0,1,num=N_Group)\n",
    "x_axis_cum=np.linspace(0,1,num=N_Group+1)\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "for j in np.arange(N_sample):\n",
    "    sample_l2_j =[]\n",
    "    sample_ks_j =[]\n",
    "    for t in np.arange(time_series_points+1):\n",
    "        #axs[0,0].hist(Frag_time_series[j][t],N_Group)\n",
    "        #axs[0,0].plot(x_axis_emp, average_emp_mass[t],label=\"T=\"+str(t*Big_time_scale) + \", Average\", linestyle='dashed')\n",
    "        #axs[0,0].set_ylim(0,40)\n",
    "        #axs[0,0].legend()\n",
    "        #axs[0,0].set_title(\"Fragment Count, Sample =\" +str(j))\n",
    "        #axs[1,0].plot(x_axis_cum, average_cum_count[t],label=\"T=\"+str(t*Big_time_scale) + \", Average\", linestyle='dashed')\n",
    "        #axs[1,0].set_ylim(0,350)\n",
    "        #axs[1,0].plot(x_axis_cum, cum_dist(Frag_time_series[j][t],N_Group)[1],label=\"T=\"+str(t*Big_time_scale), alpha=0.75)\n",
    "        #axs[1,0].legend()\n",
    "        #axs[1,0].set_title(\"Cumulative Count, Sample =\" +str(j))\n",
    "        #fig.tight_layout()\n",
    "        #display(fig)\n",
    "        #clear_output(wait = True)\n",
    "        #plt.pause(0.1)\n",
    "        #axs[0,0].cla()\n",
    "        #axs[1,0].cla()\n",
    "        sample_t_cum_count = cum_dist(Frag_time_series[j][t],N_Group)[1]\n",
    "        sample_t_emp_mass =  cum2dens(sample_t_cum_count)[1]\n",
    "        sample_t_KS_dist = round(np.linalg.norm(sample_t_cum_count-average_cum_count[t],np.inf),2)\n",
    "        sample_t_l2_dist = round(np.linalg.norm(sample_t_emp_mass-average_emp_mass[t]),2)\n",
    "        axs[0,1].plot(t*Big_time_scale,sample_t_l2_dist, marker='x', color='k', alpha=0.05)\n",
    "        axs[0,1].set_title(\"l-2 dist to mean frag count\")\n",
    "        axs[0,1].set_ylim(0,30)\n",
    "        axs[1,1].plot(t*Big_time_scale,sample_t_KS_dist, marker='x', color='k', alpha=0.05)\n",
    "        axs[1,1].set_title(\"sup dist to mean cum dist\")\n",
    "        axs[1,1].set_ylim(0,100)\n",
    "        sample_l2_j.append(sample_t_l2_dist)\n",
    "        sample_ks_j.append(sample_t_KS_dist)\n",
    "    \n",
    "    sample_l2.append(sample_l2_j)\n",
    "    sample_ks.append(sample_ks_j)\n",
    "fig.tight_layout()\n",
    "#plt.savefig('l2_sup_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e781d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d94f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sample_l2\n",
    "%store sample_ks\n",
    "\n",
    "sample_l2_final=[sample_l2[i][-1] for i in np.arange(N_sample)]\n",
    "sample_ks_final=[sample_ks[i][-1] for i in np.arange(N_sample)]\n",
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].hist(sample_l2_final,N_Group)\n",
    "axs[0].set_title(\"l2 distance to mean fragment distribution\")\n",
    "axs[1].hist(sample_ks_final,N_Group)\n",
    "axs[1].set_title(\"sup distance to mean cumulative distribution\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d464ccb",
   "metadata": {},
   "source": [
    "The plots above show that the KS distance (supremum distance) between our samples and the equilibrium distribution clearly decreases as $T$ grows larger. It may be a useful statistics in measuring the rate of convergence towards the equilibrium distribution for our Markov processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fbaf3",
   "metadata": {},
   "source": [
    "## Mixing Time\n",
    "\n",
    "For simulation and theoretical purposes, it is important to know a priori when the Markov chain has become well mixed, i.e. close to equilibrium distribution. \n",
    "\n",
    "One possible way is to study the l_2 /KS distance between the empirical distributions between two time steps, and consider the Markov chain to be well-mixed if the distance is sufficiently close. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c63ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_matrix = np.asarray(l2_dataset)\n",
    "np.mean(l2_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_matrix = np.asarray(KS_dataset)\n",
    "np.mean(KS_matrix, axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5262425",
   "metadata": {},
   "source": [
    "This seems to suggest that both l2 metric and KS metric stabilises quickly to some region. How do we get this region? Is it a good indicator that our Markov chain is well-mixed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2d8b0",
   "metadata": {},
   "source": [
    "# Further To-Do Lists\n",
    "\n",
    "Trace the Mixing Time by comparing sample to running mean\n",
    "\n",
    "Add Neutral Marker to each immigrated fragment to analyse descendant sizes at mixture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ba63b",
   "metadata": {},
   "source": [
    "# Approximate Bayesian Computation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba4be4",
   "metadata": {},
   "source": [
    "#============ Initialisation of chain length and the proposal distribution =================\n",
    "mcmc_steps = 1000\n",
    "\n",
    "mutation_rate = true_mutation_rate\n",
    "recombination_rate = true_recombination_rate\n",
    "growth_rate = true_growth_rate\n",
    "\n",
    "mutation_proposal_variance = mutation_rate / 3\n",
    "recombination_proposal_variance = recombination_rate / 3\n",
    "growth_proposal_variance = growth_rate / 3\n",
    "\n",
    "target_acceptance_rate = 0.1\n",
    "acceptance_rate = 0\n",
    "\n",
    "#============ Main loop simulating chain steps =================\n",
    "for i in range(1, mcmc_steps):\n",
    "    # ================== Sample new parameters from proposal distribution ====================\n",
    "    proposed_mutation_rate = random.gauss(mutation_rate, math.sqrt(mutation_proposal_variance))\n",
    "    if proposed_mutation_rate < 0:\n",
    "        proposed_mutation_rate = -proposed_mutation_rate\n",
    "        \n",
    "    recombination_ceiling = 5 * true_recombination_rate\n",
    "    proposed_recombination_rate = random.gauss(recombination_rate, math.sqrt(recombination_proposal_variance))\n",
    "    while proposed_recombination_rate < 0 or proposed_recombination_rate > recombination_ceiling:\n",
    "        if proposed_recombination_rate < 0:\n",
    "            proposed_recombination_rate = -proposed_recombination_rate\n",
    "        if proposed_recombination_rate > recombination_ceiling:\n",
    "            proposed_recombination_rate = 2 * recombination_ceiling - proposed_recombination_rate\n",
    "        \n",
    "    proposed_growth_rate = random.gauss(growth_rate, math.sqrt(growth_proposal_variance))\n",
    "    if proposed_growth_rate < 0:\n",
    "        proposed_growth_rate = -proposed_growth_rate\n",
    "    \n",
    "    # ================== Generate simulated data with proposed parameters ====================\n",
    "    proposed_demography = msprime.Demography.island_model([1],\n",
    "                                                          migration_rate = 0,\n",
    "                                                          growth_rate = [proposed_growth_rate])\n",
    "    simulated_trees = msprime.sim_ancestry(samples = sample_size / 2,\n",
    "                                           discrete_genome = False,\n",
    "                                           demography = proposed_demography,\n",
    "                                           recombination_rate = proposed_recombination_rate,\n",
    "                                           sequence_length = sequence_length)\n",
    "    simulated_trees = msprime.mutate(simulated_trees,\n",
    "                                     rate = proposed_mutation_rate)\n",
    "    simulated_sfs = simulated_trees.allele_frequency_spectrum(mode='site',\n",
    "                                                              span_normalise=False,\n",
    "                                                              polarised=True)\n",
    "    simulated_segregating_sites = simulated_trees.num_mutations\n",
    "    simulated_sfs = simulated_sfs[1:sample_size] / max(simulated_segregating_sites, 1)\n",
    "    simulated_logit_sfs = numpy.array([math.log(max(j, epsilon)) - math.log(max(1 - j, epsilon)) for j in simulated_sfs])\n",
    "    \n",
    "    simulated_ld = tskit.LdCalculator(true_trees).r2_array(1)\n",
    "    simulated_ld_percentiles = [numpy.quantile(simulated_ld, p) for p in numpy.linspace(0,1,11)]\n",
    "    \n",
    "    # ============ Compute distance between observed & simulated statistics =============\n",
    "    distance = math.sqrt((true_segregating_sites - simulated_segregating_sites)**2\n",
    "                         + numpy.dot(numpy.subtract(true_logit_sfs, simulated_logit_sfs),\n",
    "                                     numpy.subtract(true_logit_sfs, simulated_logit_sfs))\n",
    "                         + numpy.dot(numpy.subtract(true_ld_percentiles, simulated_ld_percentiles),\n",
    "                                     numpy.subtract(true_ld_percentiles, simulated_ld_percentiles)))\n",
    "    \n",
    "    # ============ Set up an initial distance tolerance so that first proposal gets accepted ==============\n",
    "    accepted = 0\n",
    "    if i == 1:\n",
    "        tolerance = distance\n",
    "        running_mutation_mean = (mutation_rate + proposed_mutation_rate) / 2\n",
    "        running_recombination_mean = (recombination_rate + proposed_recombination_rate) / 2\n",
    "        running_growth_mean = (growth_rate + proposed_growth_rate) / 2\n",
    "    # =========== Accept new parameters if simulated data within tolerance ====================\n",
    "    if distance <= tolerance:\n",
    "        mutation_rate = proposed_mutation_rate\n",
    "        recombination_rate = proposed_recombination_rate\n",
    "        growth_rate = proposed_growth_rate\n",
    "        acceptance_rate = ((i - 1) * acceptance_rate + 1) / i\n",
    "        accepted = 1\n",
    "    else:\n",
    "        acceptance_rate = (i - 1) * acceptance_rate / i\n",
    "    if i > 1:\n",
    "        # ======== Adapt proposal variances and acceptance tolerance to ensure chain mixes well ===============\n",
    "        eta = 1 / i**(2/3)\n",
    "        mutation_proposal_variance = (1 - eta) * mutation_proposal_variance + eta * (mutation_rate - running_mutation_mean)**2\n",
    "        recombination_proposal_variance = (1 - eta) * recombination_proposal_variance + eta * (recombination_rate - running_recombination_mean)**2\n",
    "        growth_proposal_variance = (1 - eta) * growth_proposal_variance + eta * (growth_rate - running_growth_mean)**2\n",
    "        tolerance = math.exp(math.log(tolerance) + eta * (target_acceptance_rate - accepted))\n",
    "            \n",
    "    # ======= Output the state of the chain at each iteration ========================\n",
    "    print(mutation_rate, recombination_rate, growth_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c393b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6e88bd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def frag_pieces(L, Nsplit):\n",
    "    \"frag_pieces gives the lengths of fragments after a fragment of length L is split into Nsplit pieces uniformly.\"\n",
    "    frag_interval=np.array([0,L]) \n",
    "    frag_site=np.sort(np.append(np.random.uniform(0,L,Nsplit-1),frag_interval)) #splitting positions are uniformly distributed \n",
    "    #print(frag_site)\n",
    "    frag_sizes=np.diff(frag_site)\n",
    "    frag_pieces=frag_sizes\n",
    "    # retain_size=np.random.exponential(theta, Nsplit)\n",
    "    # frag_pieces= np.less(retain_size,frag_sizes)*frag_sizes #Compare fragmentation sizes with retain size, if frag_size > retain_size, fragment remains\n",
    "    return frag_pieces\n",
    "\n",
    "def frags_split(fragments,i,Nsplit): \n",
    "    \"frags_split deletes the i-th fragment in a list of fragments and replaced it with new fragments using frag_pieces\"\n",
    "    new_frag_pieces=frag_pieces(fragments[i],Nsplit)#new fragments given by fragmenting the i-th piece\n",
    "    #print(new_frag_pieces)\n",
    "    new_frags = np.append(np.delete(fragments,i),new_frag_pieces)#i-th piece removed, replaced by new fragment pieces\n",
    "    new_frags = [i for i in new_frags if i!= 0]\n",
    "    return new_frags\n",
    "\n",
    "def frags_exit(fragments,exit_rates):\n",
    "    \"frags_exit determines which fragment exits the system and delete it from original list\"\n",
    "    exit_prob=exit_rates/np.linalg.norm(exit_rates,1)\n",
    "    frag_gone=np.random.choice(fragments.size, 1, p=exit_prob)[0] #the gone fragment is chosen with probability proportional to exit_prob\n",
    "    frags_exit=np.delete(fragments,frag_gone) #gone fragment deleted from existing system\n",
    "    return frags_exit\n",
    "\n",
    "def frag_imm(Nimm): \n",
    "    \"frag_imm returns Nimm many fragments with length of i.i.d. Uni[0,1] distribution. Nimm: number of immigrating fragments\" \n",
    "    imm_frags=np.random.uniform(0,1,Nimm) #Immigrating N fragments with length uniformly smapled between 0 and 1\n",
    "    return imm_frags\n",
    "\n",
    "def frag_mechan(fragments, ex_max, ex_slope, frag_speed, Nsplit, Nimm, imm_rate):\n",
    "    \"frag_mechan determines the next event type, the event time and a new list of fragments after the event. The events can be immigration, fragmentation and exit.\"\n",
    "    exit_rates=exit_rate(fragments, ex_max, ex_slope)\n",
    "    next_exit_time = np.random.exponential(1/np.sum(exit_rates))\n",
    "    next_frag_time = frag_time(fragments,frag_speed)\n",
    "    next_imm_time=np.random.exponential(1/imm_rate)\n",
    "    event_times = np.asarray([next_frag_time,next_exit_time,next_imm_time])\n",
    "    #print(event_times)\n",
    "    next_event=np.where(event_times == np.amin(event_times))[0]  \n",
    "    if next_event[0]==0:\n",
    "        Event= \"fragmentation\"\n",
    "        frag_gone = np.random.choice(fragments.size, 1, p=fragments/np.linalg.norm(fragments,1))[0] #probability of a fragment splitting is proportional to its length\n",
    "        new_fragments = np.asarray(frags_split(fragments,frag_gone, Nsplit))\n",
    "    elif next_event[0]==1:\n",
    "        Event= \"exit\"\n",
    "        new_fragments = frags_exit(fragments, exit_rates)\n",
    "    else:\n",
    "        Event= \"Immigration\"\n",
    "        new_fragments = np.append(fragments,frag_imm(Nimm))\n",
    "    #print(Event)    \n",
    "    return Event, np.amin(event_times), new_fragments\n",
    "\n",
    "def cum_dist(self, N_Group, count=False): \n",
    "        \"cum_dist gives the empirical cumulative distribution function of fragment lengths given a list of fragments with N_Group data points\"\n",
    "        N_tiles=np.linspace(0,1,N_Group+1)\n",
    "        #print(N_tiles)\n",
    "        cum_count=np.asarray([np.count_nonzero(self.Frag_lens<=i) for i in N_tiles])\n",
    "        cum_dist=cum_count/cum_count[-1]\n",
    "        if count:\n",
    "            output = cum_count\n",
    "        else:\n",
    "            output = cum_dist\n",
    "        return  output\n",
    "\n",
    "def cum2dens(cum_count):\n",
    "    \"cum2dens gives the empirical distribution and empirical mass of a sample with known empirical cumulative counts\"\n",
    "    i=0\n",
    "    emp_mass=np.zeros(len(cum_count)-1)\n",
    "    while i < len(cum_count)-1:\n",
    "        emp_mass[i]=cum_count[i+1]-cum_count[i]\n",
    "        i=i+1\n",
    "    emp_dens = emp_mass/np.linalg.norm(emp_mass,1)\n",
    "    return emp_dens, emp_mass\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
